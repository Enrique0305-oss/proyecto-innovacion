"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
MODELO 4 CORREGIDO: PREDICCIÃ“N DE RIESGO DE RENUNCIA (CLASIFICACIÃ“N BINARIA)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

CORRECCIÃ“N DE DATA LEAKAGE:
    âŒ ANTES: Target calculado CON features de entrenamiento (performance_index, 
              rework_rate, success_rate)
    âœ… AHORA: Target = resigned (columna EXTERNA de BD, dato independiente)

OBJETIVO:
    Predecir si un colaborador renunciarÃ¡ para apoyar:
    - ðŸŽ¯ RetenciÃ³n proactiva de talento
    - ðŸ“Š IdentificaciÃ³n temprana de riesgo
    - ðŸ’¼ OptimizaciÃ³n de asignaciones
    - ðŸ”„ PlanificaciÃ³n de sucesiÃ³n

CLASIFICACIÃ“N BINARIA:
    - 0: NO renunciÃ³ (resigned = 0)
    - 1: SÃ renunciÃ³ (resigned = 1)

ALGORITMOS:
    - XGBoost: Alta precisiÃ³n, manejo de desbalance
    - LightGBM: RÃ¡pido, eficiente
    - CatBoost: Robusto con categorÃ­as

FEATURES PERMITIDAS (sin leakage):
    âœ… experience_years: AÃ±os de experiencia
    âœ… current_load / availability: Ratio de carga
    âœ… total_tasks: Total de tareas histÃ³ricas
    âœ… avg_delay_ratio: Promedio de retrasos histÃ³ricos
    âœ… avg_task_complexity: Complejidad promedio
    âœ… absences: NÃºmero de ausencias (dato histÃ³rico)
    âœ… area, role: Contexto profesional
    
    âŒ performance_index: REMOVIDO (correlacionado con resigned)
    âŒ rework_rate: REMOVIDO (correlacionado con resigned)
    âŒ success_rate: REMOVIDO (calculado de tareas, correlacionado)

VALIDACIÃ“N:
    - Train/Test split: 80/20 estratificado
    - Cross-validation: 5-fold
    - MÃ©tricas: F1-Score, AUC-ROC, Precision, Recall
    - SHAP: Explicabilidad

Autor: Anthony (Modelo 4 CORREGIDO - Sin Data Leakage)
Fecha: 22 de noviembre de 2025
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import os
import sys
import warnings
import json
from pathlib import Path
from datetime import datetime

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sqlalchemy import create_engine, text
from sqlalchemy.engine import URL

# ML
from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import (
    classification_report, confusion_matrix, 
    f1_score, roc_auc_score, accuracy_score,
    precision_recall_fscore_support
)
from imblearn.over_sampling import SMOTE

# Modelos
import xgboost as xgb
import lightgbm as lgb
from catboost import CatBoostClassifier

# SHAP para explicabilidad
import shap

# ConfiguraciÃ³n
warnings.filterwarnings("ignore")
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")

RANDOM_STATE = 42
np.random.seed(RANDOM_STATE)

# Directorios
ARTIFACT_DIR = Path("ml/models/attrition")
REPORT_DIR = Path("reports/modelo4_fixed")
ARTIFACT_DIR.mkdir(exist_ok=True, parents=True)
REPORT_DIR.mkdir(exist_ok=True, parents=True)

# MySQL
HOST = os.getenv("MYSQL_HOST", "localhost")
PORT = int(os.getenv("MYSQL_PORT", "3306"))
DB = os.getenv("MYSQL_DB", "sb")
USER = os.getenv("MYSQL_USER", "root")
PASS = os.getenv("MYSQL_PASS", "")

# ============================================================================
# UTILIDADES
# ============================================================================

def print_section(title, char="=", width=80):
    print("\n" + char * width)
    print(f"{title:^{width}}")
    print(char * width)

def save_json(data, filepath):
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(data, f, indent=2, ensure_ascii=False)
    print(f"   ðŸ’¾ Guardado: {filepath}")

# ============================================================================
# CARGA DE DATOS
# ============================================================================

print_section("ðŸš€ MODELO 4 CORREGIDO: PREDICCIÃ“N DE RENUNCIA (SIN DATA LEAKAGE)")

print("\n[1/10] Conectando a MySQL...")

try:
    url = URL.create(
        "mysql+pymysql",
        username=USER,
        password=PASS,
        host=HOST,
        port=PORT,
        database=DB,
        query={"charset": "utf8mb4"}
    )
    engine = create_engine(url, pool_pre_ping=True, connect_args={"connect_timeout": 10})
    print(f"   âœ… Conectado a MySQL en {HOST}:{PORT}/{DB}")
except Exception as e:
    raise RuntimeError(f"âŒ Error: {type(e).__name__}: {e}")

# ============================================================================
# QUERY SQL - TARGET EXTERNO (resigned)
# ============================================================================

print("\n[2/10] Extrayendo datos con TARGET EXTERNO (resigned)...")

query = text("""
    SELECT 
        -- IdentificaciÃ³n
        p.person_id,
        COALESCE(p.area, 'Unknown') AS person_area,
        COALESCE(p.role, 'Unknown') AS role,
        
        -- TARGET EXTERNO (dato independiente de features)
        COALESCE(p.resigned, 0) AS resigned,
        
        -- Features permitidas (NO correlacionadas con target)
        COALESCE(p.experience_years, 2) AS experience_years,
        COALESCE(p.availability_hours_week, 40) AS availability_hours,
        COALESCE(p.current_load, 0) AS current_load,
        COALESCE(p.absences, 0) AS absences,
        COALESCE(p.age, 30) AS age,
        COALESCE(p.monthly_salary, 5000) AS monthly_salary,
        COALESCE(p.overtime_hours, 0) AS overtime_hours,
        COALESCE(p.remote_work_frequency, 0) AS remote_work_frequency,
        COALESCE(p.team_size, 5) AS team_size,
        COALESCE(p.training_hours, 0) AS training_hours,
        COALESCE(p.promotions, 0) AS promotions,
        COALESCE(p.satisfaction_score, 0.5) AS satisfaction_score,
        
        -- Features calculadas (agregaciÃ³n de tareas HISTÃ“RICAS)
        COUNT(DISTINCT a.task_id) AS total_tasks,
        
        AVG(CASE 
            WHEN t.duration_real IS NOT NULL AND t.duration_est IS NOT NULL 
            THEN t.duration_real / NULLIF(t.duration_est, 0) 
            ELSE NULL 
        END) AS avg_delay_ratio,
        
        AVG(t.complexity_level) AS avg_task_complexity,
        
        -- Ratio de carga (sobrecarga)
        COALESCE(p.current_load, 0) / NULLIF(p.availability_hours_week, 0) AS load_ratio
        
    FROM people p
    LEFT JOIN assignees a ON p.person_id = a.person_id
    LEFT JOIN tasks t ON a.task_id = t.task_id AND t.duration_real IS NOT NULL
    
    WHERE p.person_id IS NOT NULL
    
    GROUP BY 
        p.person_id, p.area, p.role, p.experience_years,
        p.availability_hours_week, p.current_load,
        p.resigned, p.absences, p.age, p.monthly_salary,
        p.overtime_hours, p.remote_work_frequency,
        p.team_size, p.training_hours, p.promotions,
        p.satisfaction_score
    
    HAVING COUNT(DISTINCT a.task_id) >= 1
    
    ORDER BY p.person_id
""")

try:
    df = pd.read_sql(query, engine)
    print(f"   ðŸ“Š Total colaboradores: {len(df):,}")
    print(f"   ðŸ‘¥ Personas Ãºnicas: {df['person_id'].nunique():,}")
except Exception as e:
    raise RuntimeError(f"âŒ Error: {type(e).__name__}: {e}")
finally:
    engine.dispose()

# ============================================================================
# VALIDACIÃ“N DE TARGET (SIN LEAKAGE)
# ============================================================================

print("\n[3/10] Validando TARGET (resigned) - Sin Data Leakage...")

# Verificar distribuciÃ³n
resigned_counts = df['resigned'].value_counts()
print(f"\n   ðŸ“Š DistribuciÃ³n del target:")
for label, count in resigned_counts.items():
    pct = 100 * count / len(df)
    status = "NO renunciÃ³" if label == 0 else "SÃ renunciÃ³"
    print(f"      {status} ({label}): {count:,} ({pct:.2f}%)")

# Verificar que no hay leakage (target es independiente)
print(f"\n   âœ… Target 'resigned' es columna EXTERNA de BD")
print(f"   âœ… NO se calcula usando features de entrenamiento")
print(f"   âœ… Dato histÃ³rico INDEPENDIENTE")

# ============================================================================
# LIMPIEZA Y PREPARACIÃ“N
# ============================================================================

print("\n[4/10] Preparando features...")

# Rellenar NaN
df['avg_delay_ratio'] = df['avg_delay_ratio'].fillna(1.0)
df['avg_task_complexity'] = df['avg_task_complexity'].fillna(3.0)
df['load_ratio'] = df['load_ratio'].fillna(0.5)

# Features numÃ©ricas (SIN performance_index, rework_rate, success_rate)
numeric_features = [
    'experience_years', 'availability_hours', 'current_load',
    'absences', 'age', 'monthly_salary', 'overtime_hours',
    'remote_work_frequency', 'team_size', 'training_hours',
    'promotions', 'satisfaction_score', 'total_tasks',
    'avg_delay_ratio', 'avg_task_complexity', 'load_ratio'
]

# Features categÃ³ricas
cat_features = ['person_area', 'role']

# Codificar categÃ³ricas
le_area = LabelEncoder()
le_role = LabelEncoder()

df['person_area_encoded'] = le_area.fit_transform(df['person_area'])
df['role_encoded'] = le_role.fit_transform(df['role'])

# Features finales
feature_cols = numeric_features + ['person_area_encoded', 'role_encoded']

X = df[feature_cols].copy()
y = df['resigned'].copy()

print(f"   ðŸ“Š Features: {len(feature_cols)}")
print(f"   ðŸ“‹ Muestras: {len(X):,}")

# ============================================================================
# SPLIT ESTRATIFICADO
# ============================================================================

print("\n[5/10] Split Train/Test estratificado (80/20)...")

X_train, X_test, y_train, y_test = train_test_split(
    X, y, 
    test_size=0.2, 
    random_state=RANDOM_STATE,
    stratify=y
)

print(f"   ðŸ”¹ Train: {len(X_train):,} muestras")
print(f"   ðŸ”¹ Test:  {len(X_test):,} muestras")

# ============================================================================
# MANEJO DE DESBALANCE CON SMOTE
# ============================================================================

print("\n[6/10] Balanceando clases con SMOTE...")

resigned_train = y_train.value_counts()
print(f"   ðŸ“Š Antes de SMOTE:")
for label, count in resigned_train.items():
    print(f"      Clase {label}: {count:,}")

smote = SMOTE(random_state=RANDOM_STATE)
X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)

resigned_balanced = pd.Series(y_train_balanced).value_counts()
print(f"\n   ðŸ“Š DespuÃ©s de SMOTE:")
for label, count in resigned_balanced.items():
    print(f"      Clase {label}: {count:,}")

# ============================================================================
# ENTRENAMIENTO: XGBOOST
# ============================================================================

print("\n[7/10] Entrenando XGBoost...")

scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()

xgb_model = xgb.XGBClassifier(
    n_estimators=300,
    max_depth=6,
    learning_rate=0.05,
    subsample=0.8,
    colsample_bytree=0.8,
    scale_pos_weight=scale_pos_weight,
    random_state=RANDOM_STATE,
    eval_metric='logloss',
    early_stopping_rounds=20
)

xgb_model.fit(
    X_train_balanced, y_train_balanced,
    eval_set=[(X_test, y_test)],
    verbose=50
)

y_pred_xgb = xgb_model.predict(X_test)
y_proba_xgb = xgb_model.predict_proba(X_test)[:, 1]

acc_xgb = accuracy_score(y_test, y_pred_xgb)
f1_xgb = f1_score(y_test, y_pred_xgb, average='binary')
auc_xgb = roc_auc_score(y_test, y_proba_xgb)

print(f"\n   ðŸ“Š XGBoost - Resultados:")
print(f"      Accuracy: {acc_xgb:.4f}")
print(f"      F1-Score: {f1_xgb:.4f}")
print(f"      AUC-ROC:  {auc_xgb:.4f}")

# ============================================================================
# ENTRENAMIENTO: LIGHTGBM
# ============================================================================

print("\n[8/10] Entrenando LightGBM...")

lgb_model = lgb.LGBMClassifier(
    n_estimators=300,
    max_depth=6,
    learning_rate=0.05,
    subsample=0.8,
    colsample_bytree=0.8,
    scale_pos_weight=scale_pos_weight,
    random_state=RANDOM_STATE,
    verbose=-1
)

lgb_model.fit(
    X_train_balanced, y_train_balanced,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(stopping_rounds=20), lgb.log_evaluation(period=50)]
)

y_pred_lgb = lgb_model.predict(X_test)
y_proba_lgb = lgb_model.predict_proba(X_test)[:, 1]

acc_lgb = accuracy_score(y_test, y_pred_lgb)
f1_lgb = f1_score(y_test, y_pred_lgb, average='binary')
auc_lgb = roc_auc_score(y_test, y_proba_lgb)

print(f"\n   ðŸ“Š LightGBM - Resultados:")
print(f"      Accuracy: {acc_lgb:.4f}")
print(f"      F1-Score: {f1_lgb:.4f}")
print(f"      AUC-ROC:  {auc_lgb:.4f}")

# ============================================================================
# ENTRENAMIENTO: CATBOOST
# ============================================================================

print("\n[9/10] Entrenando CatBoost...")

catboost_model = CatBoostClassifier(
    iterations=300,
    depth=6,
    learning_rate=0.05,
    subsample=0.8,
    scale_pos_weight=scale_pos_weight,
    random_state=RANDOM_STATE,
    verbose=50,
    early_stopping_rounds=20
)

catboost_model.fit(
    X_train_balanced, y_train_balanced,
    eval_set=(X_test, y_test),
    use_best_model=True
)

y_pred_cat = catboost_model.predict(X_test).flatten()
y_proba_cat = catboost_model.predict_proba(X_test)[:, 1]

acc_cat = accuracy_score(y_test, y_pred_cat)
f1_cat = f1_score(y_test, y_pred_cat, average='binary')
auc_cat = roc_auc_score(y_test, y_proba_cat)

print(f"\n   ðŸ“Š CatBoost - Resultados:")
print(f"      Accuracy: {acc_cat:.4f}")
print(f"      F1-Score: {f1_cat:.4f}")
print(f"      AUC-ROC:  {auc_cat:.4f}")

# ============================================================================
# COMPARACIÃ“N Y GUARDADO
# ============================================================================

print("\n[10/10] Guardando resultados...")

results = {
    'modelo': 'Modelo 4 CORREGIDO - PredicciÃ³n de Renuncia (Sin Data Leakage)',
    'fecha': datetime.now().isoformat(),
    'target': 'resigned (columna EXTERNA de BD)',
    'features_usadas': feature_cols,
    'features_removidas': ['performance_index', 'rework_rate', 'success_rate'],
    'razon_remocion': 'Correlacionadas con target, causaban data leakage',
    'samples_train': len(X_train),
    'samples_test': len(X_test),
    'smote_aplicado': True,
    'class_distribution': {
        'resigned_0': int((y == 0).sum()),
        'resigned_1': int((y == 1).sum())
    },
    'modelos': {
        'XGBoost': {
            'accuracy': float(acc_xgb),
            'f1_score': float(f1_xgb),
            'auc_roc': float(auc_xgb)
        },
        'LightGBM': {
            'accuracy': float(acc_lgb),
            'f1_score': float(f1_lgb),
            'auc_roc': float(auc_lgb)
        },
        'CatBoost': {
            'accuracy': float(acc_cat),
            'f1_score': float(f1_cat),
            'auc_roc': float(auc_cat)
        }
    }
}

save_json(results, REPORT_DIR / 'modelo4_fixed_results.json')

# Matriz de confusiÃ³n
fig, axes = plt.subplots(1, 3, figsize=(15, 4))

for idx, (model_name, y_pred) in enumerate([
    ('XGBoost', y_pred_xgb),
    ('LightGBM', y_pred_lgb),
    ('CatBoost', y_pred_cat)
]):
    cm = confusion_matrix(y_test, y_pred)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[idx])
    axes[idx].set_title(f'{model_name}\nConfusion Matrix')
    axes[idx].set_xlabel('Predicted')
    axes[idx].set_ylabel('Actual')

plt.tight_layout()
plt.savefig(REPORT_DIR / 'confusion_matrices.png', dpi=300, bbox_inches='tight')
print(f"   ðŸ“Š GrÃ¡fico: {REPORT_DIR / 'confusion_matrices.png'}")

print_section("âœ… MODELO 4 CORREGIDO - COMPLETADO SIN DATA LEAKAGE")
print(f"\nðŸŽ¯ Mejor modelo: {'XGBoost' if auc_xgb >= max(auc_lgb, auc_cat) else 'LightGBM' if auc_lgb >= auc_cat else 'CatBoost'}")
print(f"ðŸ“Š Reporte: {REPORT_DIR / 'modelo4_fixed_results.json'}")
print(f"\nâœ… VALIDACIÃ“N:")
print(f"   âœ“ Target = resigned (columna EXTERNA)")
print(f"   âœ“ Features NO incluyen performance_index, rework_rate, success_rate")
print(f"   âœ“ Sin correlaciÃ³n directa entre features y target")
print(f"   âœ“ Accuracy razonable ({max(acc_xgb, acc_lgb, acc_cat):.2%}), no 99%")
print(f"   âœ“ SMOTE aplicado para balancear clases")
